import cv2
import os
import numpy as np
from PIL import Image
import torch
from torchvision import transforms
from tqdm import tqdm

class VideoFrameExtractor:
    """
    Class Ä‘á»ƒ extract frames tá»« video cho training emotion recognition
    """
    
    def __init__(self, output_size=(224, 224)):
        self.output_size = output_size
        self.emotion_labels = {
            'buon': 0,      # Buá»“n
            'vui': 1,       # Vui
            'kho_chiu': 2,  # KhÃ³ chá»‹u
            'tuc_gian': 3,  # Tá»©c giáº­n
            'bat_ngo': 4    # Báº¥t ngá»
        }
    
    def extract_frames_from_video(self, video_path, max_frames=30):
        """
        Extract frames tá»« má»™t video
        
        Args:
            video_path: ÄÆ°á»ng dáº«n video
            max_frames: Sá»‘ frame tá»‘i Ä‘a extract
        
        Returns:
            list: Danh sÃ¡ch frames Ä‘Ã£ resize
        """
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"Lá»—i: KhÃ´ng thá»ƒ má»Ÿ video {video_path}")
            return []
        
        frames = []
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        # TÃ­nh step Ä‘á»ƒ láº¥y frames Ä‘á»u nhau
        if total_frames <= max_frames:
            step = 1
        else:
            step = total_frames // max_frames
        
        frame_indices = range(0, total_frames, step)[:max_frames]
        
        for frame_idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            
            if ret:
                # Convert BGR to RGB
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # Resize frame
                frame = cv2.resize(frame, self.output_size)
                frames.append(frame)
        
        cap.release()
        return frames
    
    def process_dataset(self, data_folder, output_folder, max_frames_per_video=30):
        """
        Xá»­ lÃ½ toÃ n bá»™ dataset video thÃ nh frames Ä‘á»ƒ training
        
        Args:
            data_folder: Folder chá»©a video theo cáº¥u trÃºc:
                        data_folder/
                        â”œâ”€â”€ buon/
                        â”‚   â”œâ”€â”€ video1.mp4
                        â”‚   â””â”€â”€ video2.mp4
                        â”œâ”€â”€ vui/
                        â”‚   â”œâ”€â”€ video1.mp4
                        â”‚   â””â”€â”€ video2.mp4
                        â””â”€â”€ ...
            output_folder: Folder lÆ°u frames Ä‘Ã£ extract
            max_frames_per_video: Sá»‘ frame tá»‘i Ä‘a extract tá»« má»—i video
        """
        print("ğŸ¬ Báº¯t Ä‘áº§u xá»­ lÃ½ dataset video...")
        
        # Táº¡o folder output
        os.makedirs(output_folder, exist_ok=True)
        
        total_frames = 0
        
        for emotion in self.emotion_labels.keys():
            emotion_folder = os.path.join(data_folder, emotion)
            output_emotion_folder = os.path.join(output_folder, emotion)
            
            if not os.path.exists(emotion_folder):
                print(f"âš ï¸  KhÃ´ng tÃ¬m tháº¥y folder: {emotion_folder}")
                continue
            
            os.makedirs(output_emotion_folder, exist_ok=True)
            
            # Láº¥y danh sÃ¡ch video files
            video_files = [f for f in os.listdir(emotion_folder) 
                          if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]
            
            print(f"ğŸ“ Xá»­ lÃ½ emotion '{emotion}': {len(video_files)} videos")
            
            frame_count = 0
            
            for video_file in tqdm(video_files, desc=f"Processing {emotion}"):
                video_path = os.path.join(emotion_folder, video_file)
                
                # Extract frames
                frames = self.extract_frames_from_video(video_path, max_frames_per_video)
                
                # LÆ°u frames
                video_name = os.path.splitext(video_file)[0]
                
                for i, frame in enumerate(frames):
                    frame_filename = f"{video_name}_frame_{i+1:03d}.jpg"
                    frame_path = os.path.join(output_emotion_folder, frame_filename)
                    
                    # Convert numpy array to PIL Image and save
                    pil_image = Image.fromarray(frame)
                    pil_image.save(frame_path, quality=95)
                    frame_count += 1
            
            print(f"   âœ… ÄÃ£ extract {frame_count} frames cho emotion '{emotion}'")
            total_frames += frame_count
        
        print(f"\nğŸ‰ HoÃ n thÃ nh! Tá»•ng cá»™ng {total_frames} frames Ä‘Ã£ Ä‘Æ°á»£c extract")
        print(f"ğŸ“ Frames Ä‘Æ°á»£c lÆ°u táº¡i: {output_folder}")
        
        # Hiá»ƒn thá»‹ thá»‘ng kÃª
        self.show_dataset_stats(output_folder)
    
    def show_dataset_stats(self, dataset_folder):
        """
        Hiá»ƒn thá»‹ thá»‘ng kÃª dataset
        """
        print("\nğŸ“Š THá»NG KÃŠ DATASET:")
        print("-" * 40)
        
        total_images = 0
        
        for emotion in self.emotion_labels.keys():
            emotion_folder = os.path.join(dataset_folder, emotion)
            
            if os.path.exists(emotion_folder):
                image_files = [f for f in os.listdir(emotion_folder) 
                              if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                count = len(image_files)
                total_images += count
                
                print(f"{emotion.upper():>10}: {count:>6} images")
        
        print("-" * 40)
        print(f"{'TOTAL':>10}: {total_images:>6} images")
        
        if total_images > 0:
            print(f"\nPhÃ¢n bá»‘:")
            for emotion in self.emotion_labels.keys():
                emotion_folder = os.path.join(dataset_folder, emotion)
                if os.path.exists(emotion_folder):
                    image_files = [f for f in os.listdir(emotion_folder) 
                                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                    percentage = (len(image_files) / total_images) * 100
                    print(f"  {emotion}: {percentage:.1f}%")

def main():
    """
    Main function Ä‘á»ƒ cháº¡y data preprocessing
    """
    print("=" * 60)
    print("ğŸ¯ EMOTION RECOGNITION - DATA PREPROCESSING")
    print("=" * 60)
    
    # Khá»Ÿi táº¡o extractor
    extractor = VideoFrameExtractor(output_size=(224, 224))
    
    # ÄÆ°á»ng dáº«n folders
    # Thay Ä‘á»•i Ä‘Æ°á»ng dáº«n nÃ y theo cáº¥u trÃºc folder cá»§a báº¡n
    data_folder = "data/videos"  # Folder chá»©a video gá»‘c
    output_folder = "data/frames"  # Folder lÆ°u frames
    
    print(f"ğŸ“ Input folder: {data_folder}")
    print(f"ğŸ“ Output folder: {output_folder}")
    print("\nğŸ“ Cáº¥u trÃºc folder cáº§n cÃ³:")
    print("data/videos/")
    print("â”œâ”€â”€ buon/")
    print("â”‚   â”œâ”€â”€ video1.mp4")
    print("â”‚   â””â”€â”€ video2.mp4")
    print("â”œâ”€â”€ vui/")
    print("â”‚   â”œâ”€â”€ video1.mp4") 
    print("â”‚   â””â”€â”€ video2.mp4")
    print("â”œâ”€â”€ kho_chiu/")
    print("â”œâ”€â”€ tuc_gian/")
    print("â””â”€â”€ bat_ngo/")
    
    # Kiá»ƒm tra folder tá»“n táº¡i
    if not os.path.exists(data_folder):
        print(f"\nâŒ Folder '{data_folder}' khÃ´ng tá»“n táº¡i!")
        print("ğŸ“ HÃ£y táº¡o folder vÃ  Ä‘áº·t video theo cáº¥u trÃºc trÃªn")
        return
    
    # Báº¯t Ä‘áº§u xá»­ lÃ½
    extractor.process_dataset(
        data_folder=data_folder,
        output_folder=output_folder,
        max_frames_per_video=30  # Extract tá»‘i Ä‘a 30 frames/video
    )
    
    print("\nâœ… Data preprocessing hoÃ n thÃ nh!")
    print("ğŸš€ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y training script!")

if __name__ == "__main__":
    main()
